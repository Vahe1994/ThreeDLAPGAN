{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import sys\n",
    "sys.path.append(\"/home/service/\")\n",
    "from ThreeDLAPGAN.external.LGan.src.ae_templates import mlp_architecture_ala_iclr_18, default_train_params\n",
    "from ThreeDLAPGAN.external.LGan.src.autoencoder import Configuration as Conf\n",
    "from ThreeDLAPGAN.external.LGan.src.point_net_ae import PointNetAutoEncoder\n",
    "\n",
    "from  ThreeDLAPGANexternal.LGan..src.in_out import snc_category_to_synth_id, create_dir, PointCloudDataSet, \\\n",
    "                                        load_all_point_clouds_under_folder\n",
    "from  ThreeDLAPGANexternal.LGan..src.in_out import  PointCloudDataSet\n",
    "from  ThreeDLAPGAN.src.preprocessing import  smart_upsampling,smart_downsampling,read_pickle_data,pickle_data,\\\n",
    "                                                Train_AE,Restore_AE,get_latent,get_encode_decode\n",
    "from ThreeDLAPGAN.src.graphics import get_plot\n",
    "from ThreeDLAPGAN.src.class_gan import GAN\n",
    "from ThreeDLAPGAN.src.pytorch_generator_disscriminator import sample_noise,Generator,Discriminator,UnitNormClipper,\\\n",
    "                                        g_loss,d_loss,iterate_minibatches\n",
    "\n",
    "import tqdm\n",
    "import plotly\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_out_dir = '../data/'                        # Use to write Neural-Net check-points etc.\n",
    "top_in_dir = '../data/shape_net_core_uniform_samples_2048/' # Top-dir of where point-clouds are stored.\n",
    "\n",
    "experiment_name = 'single_class_ae'\n",
    "n_pc_points = 2048                              # Number of points per model.\n",
    "bneck_size = 128                                # Bottleneck-AE size\n",
    "ae_loss = 'emd'                             # Loss to optimize: 'emd' or 'chamfer'\n",
    "class_name = raw_input('Give me the class name (e.g. \"car\"): ').lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "class_dir = osp.join(top_in_dir , syn_id)\n",
    "print(class_dir)\n",
    "all_pc_data = load_all_point_clouds_under_folder(class_dir, n_threads=8, file_ending='.ply', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf(experiment_name = 'AE2048',n_pc_points = 2048,bneck_size = 128,epoch=500,held_out_step = 10,z_rotate=False ):\n",
    "    top_out_dir = '../data/'                        # Use to write Neural-Net check-points etc.\n",
    "    top_in_dir = '../data/shape_net_core_uniform_samples_2048/' # Top-dir of where point-clouds are stored.\n",
    "    ae_loss = 'emd'                             # Loss to optimize: 'emd' or 'chamfer'\n",
    "    train_dir = create_dir(osp.join(top_out_dir, experiment_name))\n",
    "    train_params = default_train_params()\n",
    "    encoder, decoder, enc_args, dec_args = mlp_architecture_ala_iclr_18(n_pc_points, bneck_size)\n",
    "    conf = Conf(n_input = [n_pc_points, 3],\n",
    "                loss = ae_loss,\n",
    "                training_epochs = epoch,\n",
    "                batch_size = train_params['batch_size'],\n",
    "                denoising = train_params['denoising'],\n",
    "                learning_rate = train_params['learning_rate'],\n",
    "                train_dir = train_dir,\n",
    "                loss_display_step = 10,\n",
    "                saver_step = train_params['saver_step'],\n",
    "                z_rotate = z_rotate,\n",
    "                encoder = encoder,\n",
    "                decoder = decoder,\n",
    "                encoder_args = enc_args,\n",
    "                decoder_args = dec_args,\n",
    "                held_out_step = held_out_step\n",
    "               )\n",
    "    conf.experiment_name = experiment_name\n",
    "#     conf.held_out_step = 5              # How often to evaluate/print out loss on held_out data (if any).\n",
    "    conf.save(osp.join(train_dir, 'configuration'))\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pclouds_smart2048 = read_pickle_data(input='pclouds_smart2048.pkl')\n",
    "# pclouds_smart1024 = read_pickle_data(input='pclouds_smart1024.pkl')\n",
    "# pclouds_smart512 = read_pickle_data(input='pclouds_smart512.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fool_downsampling(all_pc_data,pc_count=1024):\n",
    "    pclouds = np.empty([all_pc_data.point_clouds.shape[0],pc_count, all_pc_data.point_clouds.shape[2]], dtype=np.float32)\n",
    "    for i,pc in enumerate(all_pc_data.point_clouds):\n",
    "        mask = np.zeros(pc.shape[0])\n",
    "        a = np.random.choice(pc.shape[0],size = pc_count,replace=False)\n",
    "        mask[a] = 1\n",
    "        pclouds[i] = pc[mask.astype(bool)]\n",
    "    return pclouds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclouds_smart2048 = all_pc_data.point_clouds\n",
    "pclouds_smart1024 = fool_downsampling(pc_count=1024,all_pc_data=all_pc_data)\n",
    "pclouds_smart512 = fool_downsampling(pc_count=512,all_pc_data=all_pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae512 = Train_AE(train_ae = True,data = pclouds_smart512[:-1000],conf=get_conf(experiment_name = 'AE512_car_v1_0.9_128',n_pc_points = 512,bneck_size = 128 ,epoch=1000, held_out_step=10),URL = None,held_out_data = pclouds_smart512[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae1024 = Train_AE(train_ae = True,data = pclouds_smart1024[:-1000],conf=get_conf(experiment_name = 'AE1024_car_v1_0.9_128',n_pc_points = 1024,bneck_size = 128 ,epoch=1000, held_out_step=10),URL = None,held_out_data = pclouds_smart1024[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae2048 = Train_AE(train_ae = True,data = pclouds_smart2048[:-1000],conf=get_conf(experiment_name = 'AE2048_car_v1_0.9_128',n_pc_points = 2048,bneck_size = 128 ,epoch=1000, held_out_step=10),URL = None,held_out_data = pclouds_smart2048[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ae512 = Restore_AE(name ='AE512_car_v1_0.9_128',epoch = 700,conf = get_conf(experiment_name='AE512_car_v1_0.9_128',n_pc_points=512,epoch=700))\n",
    "ae1024 = Restore_AE(name ='AE1024_car_v1_0.9_128',epoch = 1000,conf = get_conf(experiment_name='AE1024_car_v1_0.9_128',n_pc_points=1024,epoch=1000))\n",
    "ae2048 = Restore_AE(name ='AE2048_car_v1_0.9_128',epoch = 1000,conf = get_conf(experiment_name='AE2048_car_v1_0.9_128',n_pc_points=2048,epoch=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot(all_pc_data.point_clouds,id_of_obj=356,mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_id = int(1.0/3.0*pclouds_smart2048.shape[0])\n",
    "start_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(128, out_dim = 128).cuda()\n",
    "discriminator = Discriminator(in_dim = 128).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _rd = Variable(torch.FloatTensor(lt)).cuda()\n",
    "# noise = Variable((torch.Tensor(sample_noise(len(lt))))).cuda()\n",
    "\n",
    "# del generator\n",
    "# del discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(discriminator(_rd).data.cpu().numpy().ravel(), normed=True)\n",
    "# plt.hist(discriminator(generator(noise)).data.cpu().numpy().ravel(), normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_lt(ae,pclouds):\n",
    "    lt = get_latent(ae=ae,feed_pc=pclouds[:200])\n",
    "    for i in np.arange(200,pclouds.shape[0],200):\n",
    "        lt =(np.concatenate((lt,get_latent(ae=ae,feed_pc=pclouds[i:i+200])),axis=0)) \n",
    "    return lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan_1 = GAN(generator,discriminator)\n",
    "lt = get_all_lt(ae512,pclouds_smart512[:-1000])\n",
    "gan_1.train(lt,num_epochs=1800,TASK = 4,k_d = 5,k_g=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_2 = Generator(256, out_dim = 128).cuda()\n",
    "discriminator_2 = Discriminator(in_dim = 128).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan_2 = GAN(generator_2,discriminator_2)\n",
    "lt_gt = get_all_lt(ae1024,pclouds_smart1024)\n",
    "lt_ups = get_all_lt(ae1024,smart_upsampling(pclouds_smart512,512,num_neighbors=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan_2.train(data=lt_gt[:-1000],inform=lt_ups[:-1000],num_epochs=1800,TASK=4,k_d = 5,k_g=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_3 = Generator(256, out_dim = 128).cuda()\n",
    "discriminator_3 = Discriminator(in_dim = 128).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_3 = GAN(generator_3,discriminator_3)\n",
    "lt_gt = get_all_lt(ae2048,pclouds_smart2048)\n",
    "lt_ups = get_all_lt(ae2048,smart_upsampling(pclouds_smart1024,1024,num_neighbors=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan_3.train(data=lt_gt[:-1000],inform=lt_ups[:-1000],num_epochs=1800,TASK=4,k_d = 5,k_g=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "their_generator = Generator(128, out_dim = 128).cuda()\n",
    "their_discriminator = Discriminator(in_dim = 128).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "their_gan = GAN(their_generator,their_discriminator)\n",
    "lt = get_all_lt(ae2048,pclouds_smart2048[:-1000])\n",
    "their_gan.train(lt,num_epochs=1800,TASK = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lapgan_generate(gan_1,gan_2,gan_3,ae512,ae1024,ae2048,count = 20):\n",
    "    noise = Variable(torch.Tensor(sample_noise(count)).cuda())\n",
    "    data_gen_1 = gan_1.generator(noise)\n",
    "    pclouds_1  = ae512.decode(data_gen_1.data.cpu().numpy())\n",
    "    lt_ups = get_all_lt(ae1024,smart_upsampling(pclouds_1,512,num_neighbors=7))\n",
    "    \n",
    "    noise = Variable(torch.cat((torch.Tensor(sample_noise(count)),torch.Tensor(lt_ups)),1).cuda())\n",
    "    data_gen_2 = gan_2.generator(noise).data.cpu().numpy()+lt_ups\n",
    "    pclouds_2  = ae1024.decode(data_gen_2)\n",
    "    lt_ups = get_all_lt(ae2048,smart_upsampling(pclouds_2,1024,num_neighbors=7))\n",
    "    \n",
    "    noise = Variable(torch.cat((torch.Tensor(sample_noise(count)),torch.Tensor(lt_ups)),1).cuda())\n",
    "    data_gen_3 = gan_3.generator(noise).data.cpu().numpy() + lt_ups\n",
    "    return data_gen_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples =pclouds_smart2048.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lt = lapgan_generate(gan_1,gan_2,gan_3,ae512,ae1024,ae2048,count=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclouds = ae2048.decode(lt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot(pclouds,id_of_obj=0,mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path as osp\n",
    "\n",
    "from ThreeDLAPGAN.external.LGan.src.evaluation_metrics import minimum_mathing_distance, \\\n",
    "jsd_between_point_cloud_sets, coverage\n",
    "\n",
    "from ThreeDLAPGAN.external.LGan.src.in_out import snc_category_to_synth_id,\\\n",
    "                                        load_all_point_clouds_under_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = Variable(torch.Tensor(sample_noise(pclouds_smart2048.shape[0])).cuda())\n",
    "their_pclouds = their_gan.generator(noise).data.cpu().numpy()\n",
    "their_pclouds = ae2048.decode(their_pclouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ref = 1000 # size of ref_pcs.\n",
    "n_sam = 1000 # size of sample_pcs.\n",
    "\n",
    "ref_pcs = pclouds_smart2048[-1000:]\n",
    "print(ref_pcs.shape)\n",
    "mine_mmd = []\n",
    "mine_cov = []\n",
    "mine_jsd = []\n",
    "\n",
    "for it in range(5):\n",
    "    \n",
    "    sample_pcs = pclouds[it*1000:it*1000+1000]\n",
    "    ae_loss = 'chamfer'  # Which distance to use for the matchings.\n",
    "    if ae_loss == 'emd':\n",
    "        use_EMD = True\n",
    "    else:\n",
    "        use_EMD = False  # Will use Chamfer instead.\n",
    "\n",
    "    batch_size = 100     # Find appropriate number that fits in GPU.\n",
    "    normalize = True     # Matched distances are divided by the number of \n",
    "                         # points of thepoint-clouds.\n",
    "\n",
    "    mmd, matched_dists = minimum_mathing_distance(sample_pcs, ref_pcs, batch_size, normalize=normalize, use_EMD=use_EMD)\n",
    "\n",
    "    cov, matched_ids = coverage(sample_pcs, ref_pcs, batch_size, normalize=normalize, use_EMD=use_EMD)\n",
    "\n",
    "    jsd = jsd_between_point_cloud_sets(sample_pcs, ref_pcs, resolution=28)\n",
    "    print mmd, cov, jsd\n",
    "    mine_mmd.append(mmd)\n",
    "    mine_cov.append(cov)\n",
    "    mine_jsd.append(jsd)\n",
    "    \n",
    "print np.mean(mine_mmd),np.mean(mine_cov),np.mean(mine_jsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ref = 1000 # size of ref_pcs.\n",
    "n_sam = 1000 # size of sample_pcs.\n",
    "\n",
    "ref_pcs = pclouds_smart2048[-1000:]\n",
    "print(ref_pcs.shape)\n",
    "their_mmd = []\n",
    "their_cov = []\n",
    "their_jsd = []\n",
    "\n",
    "for it in range(5):\n",
    "    \n",
    "    sample_pcs = their_pclouds[it*1000:it*1000+1000]\n",
    "    ae_loss = 'chamfer'  # Which distance to use for the matchings.\n",
    "    if ae_loss == 'emd':\n",
    "        use_EMD = True\n",
    "    else:\n",
    "        use_EMD = False  # Will use Chamfer instead.\n",
    "\n",
    "    batch_size = 100     # Find appropriate number that fits in GPU.\n",
    "    normalize = True     # Matched distances are divided by the number of \n",
    "                         # points of thepoint-clouds.\n",
    "\n",
    "    mmd, matched_dists = minimum_mathing_distance(sample_pcs, ref_pcs, batch_size, normalize=normalize, use_EMD=use_EMD)\n",
    "\n",
    "    cov, matched_ids = coverage(sample_pcs, ref_pcs, batch_size, normalize=normalize, use_EMD=use_EMD)\n",
    "\n",
    "    jsd = jsd_between_point_cloud_sets(sample_pcs, ref_pcs, resolution=28)\n",
    "    print mmd, cov, jsd\n",
    "    their_mmd.append(mmd)\n",
    "    their_cov.append(cov)\n",
    "    their_jsd.append(jsd)\n",
    "    \n",
    "print np.mean(their_mmd),np.mean(their_cov),np.mean(their_jsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Mine'\n",
    "print \"MMD:\",np.mean(mine_mmd),'COV:',np.mean(mine_cov),'JSD:',np.mean(mine_jsd)\n",
    "print 'Their'\n",
    "print \"MMD:\",np.mean(their_mmd),\"COV:\",np.mean(their_cov),'JSD',np.mean(their_jsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ref = pclouds_smart2048.shape[0] # size of ref_pcs.\n",
    "n_sam = pclouds_smart2048.shape[0] # size of sample_pcs.\n",
    "\n",
    "ref_pcs = pclouds_smart2048\n",
    "sample_pcs = pclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_loss = 'chamfer'  # Which distance to use for the matchings.\n",
    "\n",
    "if ae_loss == 'emd':\n",
    "    use_EMD = True\n",
    "else:\n",
    "    use_EMD = False  # Will use Chamfer instead.\n",
    "    \n",
    "batch_size = 100     # Find appropriate number that fits in GPU.\n",
    "normalize = True     # Matched distances are divided by the number of \n",
    "                     # points of thepoint-clouds.\n",
    "\n",
    "mmd, matched_dists = minimum_mathing_distance(sample_pcs, ref_pcs, batch_size, normalize=normalize, use_EMD=use_EMD)\n",
    "\n",
    "cov, matched_ids = coverage(sample_pcs, ref_pcs, batch_size, normalize=normalize, use_EMD=use_EMD)\n",
    "\n",
    "jsd = jsd_between_point_cloud_sets(sample_pcs, ref_pcs, resolution=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print mmd, cov, jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print mmd, cov, jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print mmd, cov, jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print mmd, cov, jsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Their"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print mmd, cov, jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print mmd, cov, jsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = Variable(torch.cat((torch.Tensor(sample_noise(20)),torch.Tensor(lt_ups[:20])),1).cuda())\n",
    "data_gen = gan_3.generator(noise)\n",
    "pclouds = ae2048.decode(data_gen.data.cpu().numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot(smart_upsampling(pclouds_smart1024,1024,num_neighbors=7) ,id_of_obj=0,mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot(ae2048.decode(lt_gt[:20]) ,id_of_obj=0,mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot(pclouds,id_of_obj=1,mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot(ae2048.decode(lt_ups[:20]) ,id_of_obj=0,mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 600\n",
    "noise = Variable(torch.Tensor(sample_noise(count)).cuda())\n",
    "data_gen_1 = gan_1.generator(noise)\n",
    "pclouds_1  = ae512.decode(data_gen_1.data.cpu().numpy())\n",
    "lt_ups = get_all_lt(ae1024,smart_upsampling(pclouds_1,512,num_neighbors=7))\n",
    "\n",
    "noise = Variable(torch.cat((torch.Tensor(sample_noise(count)),torch.Tensor(lt_ups)),1).cuda())\n",
    "data_gen_2 = gan_2.generator(noise).data.cpu().numpy()+lt_ups\n",
    "pclouds_2  = ae1024.decode(data_gen_2)\n",
    "lt_ups = get_all_lt(ae2048,smart_upsampling(pclouds_2,1024,num_neighbors=7))\n",
    "\n",
    "noise = Variable(torch.cat((torch.Tensor(sample_noise(count)),torch.Tensor(lt_ups)),1).cuda())\n",
    "data_gen_3 = gan_3.generator(noise).data.cpu().numpy() + lt_ups\n",
    "pclouds_3  = ae2048.decode(data_gen_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 78 820\n",
    "# 7 6111\n",
    "obj=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot(pclouds_1,id_of_obj=obj,name='tr',mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot(pclouds_2,id_of_obj=obj,name='tr',mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot(pclouds_3,id_of_obj=obj,name='tr',mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot(all_pc_data.point_clouds,id_of_obj=75,mode=False,name='similar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot(all_pc_data.point_clouds,id_of_obj=,mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get nearest neighboor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = [KernelDensity(0.05) for i in range(7000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7000):\n",
    "    kde[i].fit(pclouds_smart2048[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "arr = [kd.score(pclouds_3[7]) for kd in tqdm(kde)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for kd in kde:\n",
    "    print(kd.score(pclouds_3[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde.score(pclouds_3[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
